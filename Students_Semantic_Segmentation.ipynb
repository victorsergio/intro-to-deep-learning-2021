{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Students-Semantic Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bbv96GA7zse1e0XwUUZFtHm1iMVRzGuv",
      "authorship_tag": "ABX9TyNmd4cbrzHc4g/diG6XBsN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorsergio/intro-to-deep-learning-2021/blob/main/Students_Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "sky = np.array([128,128,128])\n",
        "building = np.array([128, 0, 0])\n",
        "road= np.array([128, 64, 128])\n",
        "sidewalk= np.array([0, 0, 192])\n",
        "fence= np.array([64, 64, 128])\n",
        "vegetation= np.array([128, 128, 0])\n",
        "pole= np.array([192, 192, 128])\n",
        "car= np.array([64, 0, 128])\n",
        "sign= np.array([192, 128, 128])\n",
        "pedestrian= np.array([64, 64, 0])\n",
        "cyclist= np.array([0, 128, 192])\n",
        "ignore= np.array([0, 0, 0])\n",
        "\n",
        "\n",
        "def rgb_to_2D_label_4_classes(label):\n",
        "    \"\"\"\n",
        "    Supply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == sky,axis=-1)] = 0\n",
        "    label_seg [np.all(label == building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==road,axis=-1)] = 1\n",
        "    label_seg [np.all(label==sidewalk,axis=-1)] = 3\n",
        "    label_seg [np.all(label==fence,axis=-1)] = 0\n",
        "    label_seg [np.all(label==vegetation,axis=-1)] = 0\n",
        "    label_seg [np.all(label==pole,axis=-1)] = 0\n",
        "    label_seg [np.all(label==car,axis=-1)] = 2\n",
        "    label_seg [np.all(label==sign,axis=-1)] = 0\n",
        "    label_seg [np.all(label==pedestrian,axis=-1)] = 0\n",
        "    label_seg [np.all(label==cyclist,axis=-1)] = 0\n",
        "    label_seg [np.all(label==ignore,axis=-1)] = 0\n",
        "  \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg\n",
        "\n",
        "\n",
        "labels_images = []\n",
        "rgb_images = []\n",
        "\n",
        "import os\n",
        "\n",
        "# You can find the dataset for Kitti segmentation here: https://data.mendeley.com/datasets/3bmmnfb4bp/1\n",
        "\n",
        "filenames = os.listdir(\"/content/drive/MyDrive/SPI 2022/CNN/kitti_semantic/train/rgb/\")\n",
        "img_path = '/content/drive/MyDrive/SPI 2022/CNN/kitti_semantic/train/rgb/'\n",
        "label_path = '/content/drive/MyDrive/SPI 2022/CNN/kitti_semantic/train/labels/'"
      ],
      "metadata": {
        "id": "sPJu4Bsx8zT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr-VDHQGsyya"
      },
      "outputs": [],
      "source": [
        "for filename in filenames:\n",
        "    \n",
        "    image=Image.open(img_path + filename)\n",
        "    image = image.resize((128, 128))\n",
        "\n",
        "    data = asarray(image)\n",
        "    rgb_images.append(data)\n",
        "\n",
        "    # labels\n",
        "    image_label=Image.open(label_path+filename).convert('RGBA')\n",
        "    image_label = image_label.resize((128, 128))\n",
        "\n",
        "    \n",
        "    background = Image.new('RGBA', (128,128), (0, 0, 0))\n",
        "  \n",
        "    alpha_composite = Image.alpha_composite(background, image_label)\n",
        "    alpha_composite=alpha_composite.convert('RGB')\n",
        "    data_label = asarray(alpha_composite)\n",
        "\n",
        "    label_ = rgb_to_2D_label_4_classes(data_label)\n",
        "\n",
        "    labels_images.append(label_)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/SPI 2022/CNN/labels_images.pkl', 'wb') as labels_file:\n",
        "    pickle.dump(labels_images, labels_file)\n",
        "\n",
        "with open('/content/drive/MyDrive/SPI 2022/CNN/rgb_images.pkl', 'wb') as rgb_file:\n",
        "    pickle.dump(rgb_images, rgb_file)\n"
      ],
      "metadata": {
        "id": "m64aUMXl-cTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open a file, where you stored the pickled data\n",
        "file = open('/content/drive/MyDrive/SPI 2022/CNN/labels_images.pkl', 'rb')\n",
        "labels_images = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "\n",
        "file = open('/content/drive/MyDrive/SPI 2022/CNN/rgb_images.pkl', 'rb')\n",
        "rgb_images = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "SNyTMCcWs6II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "%load_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "qGQ0oqkWtF0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_images_e = np.array(labels_images)\n",
        "print(labels_images_e.shape)"
      ],
      "metadata": {
        "id": "vurKFB39v-tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_images_e = np.expand_dims(labels_images, axis=3)\n",
        "print(labels_images_e.shape)"
      ],
      "metadata": {
        "id": "6ZkfUy7etw-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_images_e = np.array(rgb_images)"
      ],
      "metadata": {
        "id": "PJOqDYUrzJ4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(rgb_images_e,labels_images_e, test_size=0.1, random_state=1)\n"
      ],
      "metadata": {
        "id": "WvXMq8aCsUdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, min_delta=0.00001)"
      ],
      "metadata": {
        "id": "a27QUBEQtMBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use transfer learning, load a VGG16 model to use as decoder for U-Net\n",
        "\n",
        "base_model = # code\n",
        "base_model.trainable = # code\n",
        "base_model.summary()\n",
        "\n",
        "X_train_no_preprocessing = X_train\n",
        "\n",
        "X_train = # Use the preprocess_input function of vgg16 for training data\n",
        "X_test = # Use the preprocess_input function of vgg16 for test data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LLcXUSp38BRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the U_Net model with skip connections\n",
        "# You can see the model architecture here: https://github.com/victorsergio/intro-to-deep-learning-2021/blob/main/U-Net-VGG16-model.png\n",
        "\n",
        "def unet_model(base_model):\n",
        "   \n",
        "    \n",
        "    base_model_last =  #encoder output\n",
        "\n",
        "    #Expansive path \n",
        "    u6 = # Transpose convolution 512 filters, kernel size 2x2, strides 2,2 padding same, initializer he_normal\n",
        "    c6 = # Convolution 512 filters, kernel size 3x3, activation = relu, padding same, initializer he_normal\n",
        "    c6 = \n",
        "    c6 = \n",
        "    c6 = # Create the skip connection (concatenate with 'block5_conv3')\n",
        "    \n",
        "    u7 = # Transpose convolution 512 filters, kernel size 2x2, strides 2,2 padding same, initializer he_normal\n",
        "    c7 = # Convolution 512 filters, kernel size 3x3, activation = relu, padding same, initializer he_normal\n",
        "    c7 = \n",
        "    c7 = \n",
        "    c7 = # Create the skip connection (concatenate with 'block4_conv3'\n",
        "\n",
        "    u8 = # Transpose convolution 256 filters, kernel size 2x2, strides 2,2 padding same, initializer he_normal\n",
        "    c8 = # Convolution 256 filters, kernel size 3x3, activation = relu, padding same, initializer he_normal\n",
        "    c8 = \n",
        "    c8 = \n",
        "    c8 = # Create the skip connection (concatenate with 'block3_conv3')\n",
        "    \n",
        "    u9 = # Transpose convolution 128 filters, kernel size 2x2, strides 2,2 padding same, initializer he_normal\n",
        "    c9 = # Convolution 128 filters, kernel size 3x3, activation = relu, padding same, initializer he_normal\n",
        "    c9 = \n",
        "    c9 = # Create the skip connection (concatenate with 'block2_conv2')\n",
        "\n",
        "    u10 = # Transpose convolution 64 filters, kernel size 2x2, strides 2,2 padding same, initializer he_normal\n",
        "    c10 = # Convolution 64 filters, kernel size 3x3, activation = relu, padding same, initializer he_normal\n",
        "    c10 = \n",
        "    c10 = # Create the skip connection (concatenate with 'block1_conv2'\n",
        "   \n",
        "    last = tf.keras.layers.Conv2D(#code here#, (1, 1))(c10)\n",
        "    \n",
        "\n",
        "    return tf.keras.Model(inputs=#code here#, outputs=#code here#)"
      ],
      "metadata": {
        "id": "YMzKsqRg8rQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = #code here"
      ],
      "metadata": {
        "id": "-sBumua--rML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "GjftUMy-9zrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png')"
      ],
      "metadata": {
        "id": "rMnIK9c272I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VhjjX8zKyPD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, epochs=100, batch_size = 8, validation_split=0.2,  callbacks=[tensorboard_callback,early_stopping_callback])"
      ],
      "metadata": {
        "id": "d-6o5DD0yzjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "imgplot = plt.imshow(X_train_no_preprocessing[320])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o0jaJQony_nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.squeeze(y_train[320])\n",
        "i.shape\n",
        "plt.imshow(i,cmap='jet')"
      ],
      "metadata": {
        "id": "aHeV6mN95UNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_train)\n",
        "y_pred_arg_max = np.argmax(y_pred,axis=-1)\n",
        "\n",
        "mask = np.expand_dims(y_pred_arg_max, axis=-1)\n"
      ],
      "metadata": {
        "id": "kx8iOUf_0en_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "id": "ni1ZYVqZg3HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0].shape"
      ],
      "metadata": {
        "id": "LRtSYfGZg62K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_arg_max.shape"
      ],
      "metadata": {
        "id": "5kz0TY9o4I40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_arg_max[0])"
      ],
      "metadata": {
        "id": "3OUoqJ1UGrQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_temp = np.array(y_train)\n",
        "l_temp.shape"
      ],
      "metadata": {
        "id": "yTDFCnmm4Np0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 4\n",
        "\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=4)\n",
        "m.update_state(l_temp, y_pred_arg_max)\n",
        "\n",
        "print(\"Mean IoU = \", m.result().numpy())"
      ],
      "metadata": {
        "id": "4TYOeYRWz0kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import PIL"
      ],
      "metadata": {
        "id": "76NKNi8UjE9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_ = mask[320].squeeze()\n",
        "image_ = X_train_no_preprocessing[320]\n",
        "\n",
        "plt.imshow(image_)\n",
        "plt.imshow(mask_, alpha=0.6,cmap='jet')\n"
      ],
      "metadata": {
        "id": "QRBx0vVM4e1N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}