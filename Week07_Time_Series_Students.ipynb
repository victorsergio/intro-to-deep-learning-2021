{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week07-Time Series-Students.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18lPet-2HQP3NgLWJkofF3yWVbResKmlc",
      "authorship_tag": "ABX9TyPJNuf1tz9T96rHyoE0JPRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorsergio/intro-to-deep-learning-2021/blob/main/Week07_Time_Series_Students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R5NPwRg-Ufe"
      },
      "source": [
        "#####El código original de este tutorial pertenece a Jason Brownle. Este código fue modificado para ser una práctica educativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FsrLXj2CyH5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhB_N3oVCzqO"
      },
      "source": [
        "# LSTM model for the har dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJqkUOWSJmba"
      },
      "source": [
        "dataset_path = \"drive/My Drive/Seminario Profesional I 2021/HAR with CNN/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O6cyb5PGFIO"
      },
      "source": [
        "# run this only once to save dataset to drive\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/HAR_Smartphones.zip -P \"drive/My Drive/Seminario Profesional I 2021/HAR with CNN/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jj5h-UHN5s"
      },
      "source": [
        "!unzip -q \"drive/My Drive/Seminario Profesional I 2021/HAR with CNN/HAR_Smartphones.zip\" -d \"drive/My Drive/Seminario Profesional I 2021/HAR with CNN/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ9Ij24xf_fJ"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import datetime, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQF0Hs2qfiPW"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "# checkpoint\n",
        "#  - Especifique el callback para guardar el modelo en un archivo en cada iteración, guardando solamente el mejor modelo.\n",
        "#    https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "\n",
        "# code:\n",
        "filepath = dataset_path+'output.best.h5\n",
        "checkpoint_callback = \n",
        "\n",
        "# tensorboard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1,profile_batch=0)\n",
        "\n",
        "# callbacks\n",
        "callbacks_list = [checkpoint_callback,tensorboard_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pR2KIMAgGmp"
      },
      "source": [
        "# Run Tensorboad for monitoring\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZXofR7C__X"
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "    return dataframe.values\n",
        "\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "    loaded = list()\n",
        "\n",
        "    print(\"\\nShape dimensions:\\n\")\n",
        "    for name in filenames:\n",
        "        data = load_file(prefix + name)\n",
        "        print(np.array(loaded).shape)\n",
        "        loaded.append(data)\n",
        "      \n",
        "     \n",
        "    # stack group so that features are the 3rd dimension\n",
        "    print(np.array(loaded).shape)\n",
        "    loaded = np.dstack(loaded)\n",
        "    print(np.array(loaded).shape)\n",
        "    return loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "    filepath = prefix + group + '/Inertial Signals/'\n",
        "    # load all 9 files as a single array\n",
        "    filenames = list()\n",
        "    # total acceleration\n",
        "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "    # body acceleration\n",
        "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "    # body gyroscope\n",
        "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "    # load input data\n",
        "    X = load_group(filenames, filepath)\n",
        "    # load class output\n",
        "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "    return X, y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "    # load all train\n",
        "    trainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/')\n",
        "    # load all test\n",
        "    testX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/')\n",
        "    # zero-offset class values\n",
        "    trainy = trainy - 1\n",
        "    testy = testy - 1\n",
        "    print(\"\\nOne Hot Encoding: \\n\",trainy)\n",
        "    \n",
        "    # one hot encode y\n",
        "    \n",
        "    # - Codifique las etiquetas enteras a one hot encoding\n",
        "    #   https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
        "\n",
        "    # Code:\n",
        "\n",
        "    trainy = \n",
        "    testy = \n",
        "    print(\"\\n\",trainy)\n",
        "    return trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToE5nuXuCmYy"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "    global model\n",
        "    verbose, epochs, batch_size = 1, 10, 32\n",
        "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "    \n",
        "    # - Defina un stack de 2 capas LSTM, y la sección de clasificación adecuada (Dense).\n",
        "    #   https://www.tensorflow.org/guide/keras/sequential_model#creating_a_sequential_model\n",
        "\n",
        "    # code:\n",
        "\n",
        "    #model.add(\n",
        "        \n",
        "    #  - Especifique la función de pérdida correcta \n",
        "    # code:\n",
        "    model.compile(loss=###, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    \n",
        "    # fit network\n",
        "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose,callbacks=callbacks_list)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4nkoL6CVgtG"
      },
      "source": [
        "trainX, trainy, testX, testy = load_dataset(dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjDV3qWtVjU4"
      },
      "source": [
        "score = evaluate_model(trainX, trainy, testX, testy)\n",
        "score = score * 100.0\n",
        "print('>Accuracy: %.3f' % (score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3eBPdb3ggzI"
      },
      "source": [
        "# Reload model\r\n",
        "model = tf.keras.models.load_model(dataset_path+'output.best.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJO0de2OWHNU"
      },
      "source": [
        "print(\"\\nsample:\", testX[0])\n",
        "print(\"\\nshape: \", testX[0].shape)\n",
        "print(\"\\nground truth: \", testy[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Ag9rjdXAcS"
      },
      "source": [
        "t = testX[0]\n",
        "t = t.reshape(1,128,9)\n",
        "\n",
        "\n",
        "#print(\"\\nclass:\",model.predict_classes(t))\n",
        "result = model.predict(t)\n",
        "print(\"\\nprobs:\",result)\n",
        "\n",
        "print(\"\\npredicted class:\",np.argmax(result))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY00G_ZoRggu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}